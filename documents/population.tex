% This file is part of the Undetectable project.
% Copyright 2013 David W. Hogg (NYU)

\documentclass[12pt]{article}
\newcommand{\documentname}{\textsl{Note}}

% math operators and the like
\newcommand{\given}{\,|\,}
\newcommand{\dd}{\mathrm{d}}

% *all* math symbols will be defined!
\newcommand{\pdf}{p}
\newcommand{\setof}[1]{\left\{{#1}\right\}}
\newcommand{\data}{D_n}
\newcommand{\setofalldata}{\setof{\data}_{n=1}^N}
\newcommand{\parsymbol}{\theta}
\newcommand{\pars}{\parsymbol_n}
\newcommand{\hyperpars}{\alpha}
\newcommand{\sample}{\parsymbol_{nk}}
\newcommand{\default}[1]{{#1}^{(0)}}
\newcommand{\setofallsamples}{\setof{\sample}_{k=1}^K}
\newcommand{\amp}{A}
\newcommand{\period}{P}
\newcommand{\phase}{\phi}
\newcommand{\ampmin}{\amp_{\min}}
\newcommand{\ampmax}{\amp_{\max}}
\newcommand{\amppower}{\beta}
\newcommand{\periodmin}{\period_{\min}}
\newcommand{\periodmax}{\period_{\max}}
\newcommand{\periodpower}{\gamma}
\newcommand{\normal}{N}
\newcommand{\powerlaw}{Q}
\newcommand{\uniform}{U}

\begin{document}

\begin{abstract}
Imagine an extremely ``faint'' or low-signal astronomical source, like
some kind of very tiny exoplanet or stellar oscillation.  Imagine that
there are many of these objects out there, but that not a single one
has ever been detected significantly in \emph{any} data set.  In this
\documentname, we ask the insane question ``Given observations of
enough systems, can we confidently infer properties of the population
of sources, even if not a single one is detected in any data set?''
The answer, of course, is ``yes'': So long as enough systems have been
observed such that the sum of the squares of all the individually low
signal-to-noise ratios (in all the individually observed systems) is
large, it is possible in principle to make confident statistical
statements about the population as a whole.  The method proposed here
involves hierarchical probabilistic inference.  It works well on toy
data---in this case artificial exoplanet radial-velocity data---but it
suffers from the problem that (almost by assumption) population
inferences are hard to test with existing or new data; while parameter
estimation and model comparison are possible, informative model
checking is nearly impossible.
\end{abstract}

\section{Introduction}

Astronomers are good at looking at faint signals buried in data.
In particular, a lot has been learned by \emph{stacking data}.
If you have spectra (or photometry, or anything else) of a large number of sources
which you expect to be very similar in important ways, you can co-add or average or sum
the data.
If the noise is uncorrelated and the assumption of similarity is reasonable,
the signal-to-noise of the average or sum will increase with the square root of
the number of sources.
The stacking technique has been used to measure many faint signals, including
[example, citation], [example, citation], and [example, citation], just to name
a very few examples.
In each of these cases, the signals of interest were not visible---or not at
high enough signal-to-noise---in any individual source; it required the co-add of
many exemplars to see the signal.

Now consider the much more difficult situation in which there is something lurking
in many individual sources, but it is "out of phase" or substantially different
between one source and the next:
What if you have lots of sources in which low signal-to-noise signals are hiding, but
they don't have the property that co-addition will render them visible?
In \figurenames~\ref{fig:stack} and \ref{fig:ersatz} we show examples of two data
sets.
In the first data set---the ``stack'' set---a coherent and more-or-less identical
signal is present in every source; in the second---the ``ersatz'' set---there is
just as much \emph{total} signal, but the signals have different phases and periods.
The \figurenames\ show that the ``stack'' data can be stacked to find the hidden
signal but the ``ersatz'' sample can't.
Both data sets have the same amount of information in similar kinds of signals
in the same amount of data with the same noise properties; if we can find the signal
in the ``stack'' data, then we must be able to find it in the ``ersatz'' data as
well.

In what follows, we will show that we \emph{can} find the signal in the ``ersatz''
data, and that we can measure it with good precision and accuracy.
The method involves hierarchical modeling, and is not computationally trivial.
The method works here, but has applications in many other areas, including those
in which we want to measure distribution functions for source populations, when for
each member of the population we only have low signal-to-noise measurements.
Our solution also ought to help with the detection and analysis of signals that
meet the requirements for stacking to work.
That is, we present here the \emph{probabilistic generalization of stacking}.
It is computationally expensive, but the benefits include far more power;
in particular, we can measure the properties of a population of objects
\emph{no member of which has been individually detected}.

\section{Method}

The toy model is
\begin{eqnarray}
v_{nm}
  &=&
v_n + \amp_n\,\cos(2\pi\,\period_n^{-1}\,t_{nm} + \phase_n) + e_{nm}
\\
p(e_{nm})
  &=&
\normal(e_{nm}\given 0,\sigma_{nm}^2)
\quad,
\end{eqnarray}
where...

We made three different kinds of fake data... blank... stack... ersatz...

Hierarchical inference just moves the ``likelihood'' up one level:
\begin{eqnarray}
\data
  &\equiv&
\setof{v_{nm}}_{m=1}^{M_n}
\\
\pars
  &\equiv&
\setof{\amp, \period, \phase}
\\
\pdf(\pars\given\data,\hyperpars)
  &\equiv&
\frac{\pdf(\data\given\pars)\,\pdf(\pars\given\hyperpars)}{\pdf(\data\given\hyperpars)}
\\
\pdf(\data\given\hyperpars)
  &\equiv&
\int \pdf(\data\given\pars)\,\pdf(\pars\given\hyperpars)\,\dd\pars
\\
\pdf(\setofalldata\given\hyperpars)
  &\equiv&
\prod_{n=1}^N \pdf(\data\given\hyperpars)
\quad,
\end{eqnarray}
where...

Now imagine we have $K$ samples $\setofallsamples$ from the
posteror pdf generated with some default (standard or weakly
informative or na\"ive) hyperprior setting $\default{\hyperpars}$:
\begin{eqnarray}
\setofallsamples
 &\sim&
\pdf(\pars\given\data,\default{\hyperpars})
\\
\int f(\pars)\,\pdf(\pars\given\data,\default{\hyperpars})\,\dd\pars
 &\approx&
\frac{1}{K}\,\sum_{k=1}^K f(\sample)
\quad,
\end{eqnarray}
where...

The importance-sampling version of hierarchical inference is
obtained by:
\begin{eqnarray}
\pdf(\data\given\hyperpars)
 &\equiv&
\int \frac{\pdf(\pars\given\default{\hyperpars})}{\pdf(\pars\given\default{\hyperpars})}\,\frac{\pdf(\data\given\default{\hyperpars})}{\pdf(\data\given\default{\hyperpars})}\,\pdf(\data\given\pars)\,\pdf(\pars\given\hyperpars)\,\dd\pars
\\
\frac{\pdf(\data\given\hyperpars)}{\pdf(\data\given\default{\hyperpars})} 
 &\equiv&
\int \frac{\pdf(\pars\given\hyperpars)}{\pdf(\pars\given\default{\hyperpars})}\,\pdf(\pars\given\data,\default{\hyperpars})\,\dd\pars
\\
\frac{\pdf(\data\given\hyperpars)}{\pdf(\data\given\default{\hyperpars})} 
 &\approx&
\frac{1}{K}\,\sum_{k=1}^K \frac{\pdf(\sample\given\hyperpars)}{\pdf(\sample\given\default{\hyperpars})}
\\
\frac{\pdf(\setofalldata\given\hyperpars)}{\pdf(\setofalldata\given\default{\hyperpars})} &\equiv& \prod_{n=1}^N \frac{\pdf(\data\given\hyperpars)}{\pdf(\data\given\default{\hyperpars})}
\quad,
\end{eqnarray}
where...

...Notes about log-sum...

The hyperparameters will be parameters of power-law distributions for
parameters:
\begin{eqnarray}
\pdf(\pars\given\hyperpars)
  &=&
\powerlaw(\amp\given\ampmin,\ampmax,\amppower)\,\powerlaw(\period\given\periodmin,\periodmax,\periodpower)\,\uniform(\phase\given 0,2\pi)
\\
\powerlaw(x\given a,b,c)
  &\equiv&
\left\{\begin{array}{cl}
  0 & \mbox{for}~x < a \\
  {[b^c - a^c]}^{-1}\,c\,x^{c-1} & \mbox{for}~a < x < b \\
  0 & \mbox{for}~x > b
\end{array}\right.
\\
\uniform(x\given a,b)
  &\equiv&
\left\{\begin{array}{cl}
  0 & \mbox{for}~x < a \\
  {[b - a]}^{-1} & \mbox{for}~a < x < b \\
  0 & \mbox{for}~x > b
\end{array}\right.
\\
\uniform(x\given a,b)
  &=& \powerlaw(x\given a,b,1)
\\
\hyperpars
  &\equiv&
\setof{\ampmin, \ampmax, \amppower, \periodmin, \periodmax, \periodpower}
\quad,
\end{eqnarray}
where...

Just so we can do sampling in the hyperparameters, we have to make up
a hyper-prior:
\begin{eqnarray}
\pdf(\ampmin)
  &=&
\powerlaw(\ampmin\given\amp_1,\amp_2,0)
\\
\pdf(\ampmax)
  &=&
\powerlaw(\ampmax\given\amp_1,\amp_2,0)
\\
\ampmin &<& \ampmax
\\
\pdf(\amppower)
  &=&
\uniform(\amppower\given {-2},{+2})
\\
\pdf(\periodmin)
  &=&
\powerlaw(\periodmin\given\period_1,\period_2,0)
\\
\pdf(\periodmax)
  &=&
\powerlaw(\periodmax\given\period_1,\period_2,0)
\\
\periodmin &<& \periodmax
\\
\pdf(\periodpower)
  &=&
\uniform(\periodpower\given {-2},{+2})
\quad,
\end{eqnarray}
where...  Note that we did \emph{not} generate \emph{any} of the
ersatz data from anything like any prior permitted by these
hyperparameters and hyperpriors: The sampling distributions for the
fake data were Gaussians.

\end{document}

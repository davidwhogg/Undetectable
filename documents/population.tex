% This file is part of the Undetectable project.
% Copyright 2013 David W. Hogg (NYU)

\documentclass[12pt]{article}
\newcommand{\documentname}{\textsl{Note}}

% math operators and the like
\newcommand{\given}{\,|\,}
\newcommand{\dd}{\mathrm{d}}

% *all* math symbols will be defined!
\newcommand{\pdf}{{p}}
\newcommand{\setof}[1]{\left\{{#1}\right\}}
\newcommand{\data}{{D_n}}
\newcommand{\setofalldata}{\setof{\data}_{n=1}^N}
\newcommand{\parsymbol}{\theta}
\newcommand{\pars}{\parsymbol_n}
\newcommand{\hyperpars}{\alpha}
\newcommand{\sample}{\parsymbol_{nk}}
\newcommand{\default}[1]{{#1}^{(0)}}
\newcommand{\setofallsamplesdefault}{\setof{\default{\sample}}_{k=1}^K}

\begin{document}

\begin{abstract}
Imagine an extremely ``faint'' or low-signal astronomical source, like
some kind of very tiny exoplanet or stellar oscillation.  Imagine that
there are many of these objects out there, but that not a single one
has ever been detected significantly in \emph{any} data set.  In this
\documentname, we ask the insane question ``Given observations of
enough systems, can we confidently infer properties of the population
of sources, even if not a single one is detected in any data set?''
The answer, of course, is ``yes'': So long as enough systems have been
observed such that the sum of the squares of all the individually low
signal-to-noise ratios (in all the individually observed systems) is
large, it is possible in principle to make confident statistical
statements about the population as a whole.  The method proposed here
involves hierarchical probabilistic inference.  It works well on toy
data---in this case artificial exoplanet radial-velocity data---but it
suffers from the problem that (almost by assumption) population
inferences are hard to test with existing or new data; while parameter
estimation and model comparison are possible, informative model
checking is nearly impossible.
\end{abstract}

\section{Method}

The method for this paper involves the following crap:
\begin{eqnarray}
\pdf(\theta\given\data,\hyperpars)
  &\equiv&
\frac{\pdf(\data\given\pars)\,\pdf(\pars\given\hyperpars)}{\pdf(\data\given\hyperpars)}
\\
\pdf(\data\given\hyperpars)
  &\equiv&
\int \pdf(\data\given\pars)\,\pdf(\pars\given\hyperpars)\,\dd\pars
\\
\pdf(\setofalldata\given\hyperpars)
  &\equiv&
\prod_{n=1}^N \pdf(\data\given\hyperpars)
\quad.
\end{eqnarray}

Now imagine we have $K$ samples $\setofallsamplesdefault$ from the
posteror pdf generated with some default (standard or weakly
informative or na\"ive) hyperprior setting $\default{\hyperpars}$:
\begin{eqnarray}
\setofallsamplesdefault
 &\sim&
\pdf(\pars\given\data,\default{\hyperpars})
\\
\int f(\pars)\,\pdf(\pars\given\data,\default{\hyperpars})\,\dd\pars
 &\approx&
\frac{1}{K}\,\sum_{k=1}^K f(\sample)
\end{eqnarray}

And the importance-sampling version of hierarchical inference is
obtained by:
\begin{eqnarray}
\pdf(\data\given\hyperpars)
 &\equiv&
\int \frac{\pdf(\pars\given\default{\hyperpars})}{\pdf(\pars\given\default{\hyperpars})}\,\frac{\pdf(\data\given\default{\hyperpars})}{\pdf(\data\given\default{\hyperpars})}\,\pdf(\data\given\pars)\,\pdf(\pars\given\hyperpars)\,\dd\pars
\\
\frac{\pdf(\data\given\hyperpars)}{\pdf(\data\given\default{\hyperpars})} 
 &\equiv&
\int \frac{\pdf(\pars\given\hyperpars)}{\pdf(\pars\given\default{\hyperpars})}\,\pdf(\pars\given\data,\default{\hyperpars})\,\dd\pars
\\
\frac{\pdf(\data\given\hyperpars)}{\pdf(\data\given\default{\hyperpars})} 
 &\approx&
\frac{1}{K}\,\sum_{k=1}^K \frac{\pdf(\sample\given\hyperpars)}{\pdf(\sample\given\default{\hyperpars})}
\\
\frac{\pdf(\setofalldata\given\hyperpars)}{\pdf(\setofalldata\given\default{\hyperpars})} &\equiv& \prod_{n=1}^N \frac{\pdf(\data\given\hyperpars)}{\pdf(\data\given\default{\hyperpars})}
\quad,
\end{eqnarray}
where...

\end{document}
